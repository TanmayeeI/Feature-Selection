{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Missing Values Ratio"
      ],
      "metadata": {
        "id": "Ufn7p5CCmQlm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVOd8O2qkp-t",
        "outputId": "bcd0396e-892c-46cd-f99d-8bf4f9994867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features removed due to missing values: Index(['Price', 'Bedroom2', 'Bathroom', 'Car', 'Landsize', 'BuildingArea',\n",
            "       'YearBuilt', 'Lattitude', 'Longtitude'],\n",
            "      dtype='object')\n",
            "Reduced dataset shape: (34857, 11)\n",
            "The target variable 'Price' was removed due to missing values. No model can be trained.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "\n",
        "melbourne_data = pd.read_csv('melbourne_housing_raw.csv')\n",
        "\n",
        "# Filter out columns with more than 20% missing values\n",
        "missing_values_ratio = melbourne_data.isnull().mean() * 100\n",
        "features_to_remove = missing_values_ratio[missing_values_ratio > 20].index\n",
        "reduced_data = melbourne_data.drop(columns=features_to_remove)\n",
        "\n",
        "# Print the features removed and the shape of the reduced dataset\n",
        "print(f\"Features removed due to missing values: {features_to_remove}\")\n",
        "print(f\"Reduced dataset shape: {reduced_data.shape}\")\n",
        "\n",
        "# Check if 'Price' is still in the reduced dataset\n",
        "if 'Price' in reduced_data.columns:\n",
        "    # Step 2: Prepare features (X) and target (y)\n",
        "    X = reduced_data.drop(columns=['Price']).values  # Features\n",
        "    y = reduced_data['Price'].values  # Target variable\n",
        "\n",
        "    # Step 3: Split dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Step 4: Train Linear Regression model\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Step 5: Make predictions and evaluate using Mean Squared Error\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"Mean Squared Error after removing features with >20% missing values: {mse}\")\n",
        "else:\n",
        "    print(\"The target variable 'Price' was removed due to missing values. No model can be trained.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## High Correlation Filter"
      ],
      "metadata": {
        "id": "lBSjeJoCnF0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop non-numeric columns and keep only numeric types for correlation calculation\n",
        "numeric_data = melbourne_data.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Calculate the correlation matrix on numeric data\n",
        "correlation_matrix = numeric_data.corr()\n",
        "\n",
        "# Identify highly correlated features (correlation > 0.85)\n",
        "threshold = 0.85\n",
        "features_to_remove = set()  # Using a set to avoid duplicates\n",
        "\n",
        "for i in range(len(correlation_matrix.columns)):\n",
        "    for j in range(i):\n",
        "        if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
        "            # Add the feature with higher index to the set\n",
        "            features_to_remove.add(correlation_matrix.columns[i])\n",
        "\n",
        "# Remove the identified features from the original dataset\n",
        "reduced_data = melbourne_data.drop(columns=features_to_remove)\n",
        "\n",
        "# Print the features removed and the shape of the reduced dataset\n",
        "print(f\"Features removed due to high correlation: {features_to_remove}\")\n",
        "print(f\"Reduced dataset shape: {reduced_data.shape}\")\n",
        "\n",
        "# Check if 'Price' is still in the reduced dataset\n",
        "if 'Price' not in reduced_data.columns:\n",
        "    print(\"The target variable 'Price' was removed due to high correlation. No model can be trained.\")\n",
        "else:\n",
        "    # Drop rows with missing values\n",
        "    reduced_data = reduced_data.dropna()\n",
        "\n",
        "    # One-hot encode categorical variables\n",
        "    reduced_data = pd.get_dummies(reduced_data, drop_first=True)  # Drop first to avoid dummy variable trap\n",
        "\n",
        "    # Prepare features (X) and target (y)\n",
        "    X = reduced_data.drop(columns=['Price']).values  # Features\n",
        "    y = reduced_data['Price'].values  # Target variable\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "    # Train the Linear Regression model\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions and evaluate using Mean Squared Error\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"Mean Squared Error after removing features with high correlation: {mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AubZ0dCsnKr3",
        "outputId": "cc7eca90-f4bd-44ea-dab7-4b33306e1900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features removed due to high correlation: {'Bedroom2'}\n",
            "Reduced dataset shape: (34857, 19)\n",
            "Mean Squared Error after removing features with high correlation: 4.554932281711646e+22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Low Variance Filter"
      ],
      "metadata": {
        "id": "g4qNZ8nJnNkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out low variance features\n",
        "# Calculate variance for each numeric feature\n",
        "numeric_features = melbourne_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "variances = melbourne_data[numeric_features].var()\n",
        "\n",
        "# Select features with variance above a threshold\n",
        "low_variance_threshold = 0.01\n",
        "features_to_keep = variances[variances > low_variance_threshold].index\n",
        "\n",
        "# Keep only the features with high variance\n",
        "reduced_data = melbourne_data[features_to_keep]\n",
        "\n",
        "# Check if 'Price' is in the remaining features\n",
        "if 'Price' not in reduced_data.columns:\n",
        "    print(\"The target variable 'Price' was removed due to low variance. No model can be trained.\")\n",
        "else:\n",
        "    # Drop rows with missing values\n",
        "    reduced_data = reduced_data.dropna()\n",
        "\n",
        "    # Prepare features (X) and target (y)\n",
        "    X = reduced_data.drop(columns=['Price']).values  # Features\n",
        "    y = reduced_data['Price'].values  # Target variable\n",
        "\n",
        "    # Split dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "    # Train the Linear Regression model\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions and evaluate using Mean Squared Error\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"Mean Squared Error after removing low variance features: {mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKBcxMgOnQ78",
        "outputId": "97c32974-ff95-4c4e-d55d-7606de44487b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error after removing low variance features: 152644792220.06802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forward Feature Selection"
      ],
      "metadata": {
        "id": "BnGUIja-nULf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "# Drop rows with missing values\n",
        "melbourne_data = melbourne_data.dropna()\n",
        "\n",
        "# Select only numeric features for the regression model\n",
        "numeric_features = melbourne_data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "\n",
        "# Check if 'Price' is in numeric features\n",
        "if 'Price' in numeric_features:\n",
        "    numeric_features.remove('Price')  # Remove target variable from features\n",
        "\n",
        "# Prepare features (X) and target (y)\n",
        "X = melbourne_data[numeric_features].values  # Features\n",
        "y = melbourne_data['Price'].values  # Target variable\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Create a Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Implement Forward Feature Selection\n",
        "sfs = SequentialFeatureSelector(model,\n",
        "                                 n_features_to_select='auto',\n",
        "                                 direction='forward',\n",
        "                                 scoring='neg_mean_squared_error',\n",
        "                                 cv=5)\n",
        "\n",
        "# Fit SFS to the training data\n",
        "sfs.fit(X_train, y_train)\n",
        "\n",
        "# Get selected feature indices\n",
        "selected_features_indices = sfs.get_support(indices=True)\n",
        "\n",
        "# Get selected feature names\n",
        "selected_features = [numeric_features[i] for i in selected_features_indices]\n",
        "\n",
        "print(f\"Selected features: {selected_features}\")\n",
        "\n",
        "# Step 5: Train the model with selected features\n",
        "X_train_selected = sfs.transform(X_train)\n",
        "X_test_selected = sfs.transform(X_test)\n",
        "\n",
        "model.fit(X_train_selected, y_train)\n",
        "\n",
        "# Make predictions and evaluate using Mean Squared Error\n",
        "y_pred = model.predict(X_test_selected)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error with selected features: {mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1bmJzJOnW7K",
        "outputId": "d4932d1a-bf9f-4f84-9475-1e8d436e55aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features: ['Rooms', 'Distance', 'Bathroom', 'BuildingArea', 'YearBuilt', 'Lattitude']\n",
            "Mean Squared Error with selected features: 161414427141.72278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backward Feature Elimination"
      ],
      "metadata": {
        "id": "3jc54BnVneQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "# Drop rows with missing values\n",
        "melbourne_data = melbourne_data.dropna()\n",
        "\n",
        "# Select only numeric features for the regression model\n",
        "numeric_features = melbourne_data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "\n",
        "# Check if 'Price' is in numeric features\n",
        "if 'Price' in numeric_features:\n",
        "    numeric_features.remove('Price')  # Remove target variable from features\n",
        "\n",
        "# Prepare features (X) and target (y)\n",
        "X = melbourne_data[numeric_features].values  # Features\n",
        "y = melbourne_data['Price'].values  # Target variable\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Create a Random Forest model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Backward Feature Elimination\n",
        "remaining_features = numeric_features.copy()\n",
        "\n",
        "while len(remaining_features) > 1:  # Ensure at least one feature remains\n",
        "    # Fit the model\n",
        "    model.fit(X_train[:, :len(remaining_features)], y_train)\n",
        "\n",
        "    # Get feature importances\n",
        "    importances = model.feature_importances_\n",
        "\n",
        "    # Find the least important feature\n",
        "    least_important_index = np.argmin(importances)\n",
        "\n",
        "    # Remove the least important feature\n",
        "    least_important_feature = remaining_features[least_important_index]\n",
        "    remaining_features.remove(least_important_feature)\n",
        "\n",
        "    # Train the model on the reduced feature set\n",
        "    X_train_reduced = X_train[:, :len(remaining_features)]\n",
        "    X_test_reduced = X_test[:, :len(remaining_features)]\n",
        "\n",
        "    # Check if we still have features to train on\n",
        "    if X_train_reduced.shape[1] == 0:  # If no features left, break the loop\n",
        "        break\n",
        "\n",
        "    model.fit(X_train_reduced, y_train)\n",
        "\n",
        "    # Make predictions and evaluate the model\n",
        "    y_pred = model.predict(X_test_reduced)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    print(f\"Removed feature: {least_important_feature}, MSE: {mse}\")\n",
        "\n",
        "# Remaining features after elimination\n",
        "print(f\"Remaining features: {remaining_features}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gxDjs9bniZJ",
        "outputId": "2b1945c5-1daf-4fa9-8c81-5223783afa17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed feature: Bedroom2, MSE: 65056356982.440735\n",
            "Removed feature: Bathroom, MSE: 68518665251.77405\n",
            "Removed feature: Car, MSE: 69139475783.0304\n",
            "Removed feature: Landsize, MSE: 74938031952.27202\n",
            "Removed feature: BuildingArea, MSE: 82540180649.84428\n",
            "Removed feature: Longtitude, MSE: 114323355240.92207\n",
            "Removed feature: YearBuilt, MSE: 107082506931.72218\n",
            "Removed feature: Lattitude, MSE: 110240429939.68059\n",
            "Removed feature: Propertycount, MSE: 108820786828.80994\n",
            "Removed feature: Rooms, MSE: 176984255433.44705\n",
            "Removed feature: Distance, MSE: 311765920534.43243\n",
            "Remaining features: ['Postcode']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "y1TWvbkKnn58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "# Drop rows with missing values\n",
        "melbourne_data = melbourne_data.dropna()\n",
        "\n",
        "# Select only numeric features for the regression model\n",
        "numeric_features = melbourne_data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "\n",
        "# Check if 'Price' is in numeric features\n",
        "if 'Price' in numeric_features:\n",
        "    numeric_features.remove('Price')  # Remove target variable from features\n",
        "\n",
        "# Prepare features (X) and target (y)\n",
        "X = melbourne_data[numeric_features].values  # Features\n",
        "y = melbourne_data['Price'].values  # Target variable\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Create and train a Random Forest model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Look at feature importances\n",
        "importances = model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': numeric_features,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"Feature importances:\\n\", feature_importance_df)\n",
        "\n",
        "# Remove the least important feature and retrain the model\n",
        "least_important_feature = feature_importance_df.tail(1)['Feature'].values[0]\n",
        "remaining_features = numeric_features.copy()\n",
        "remaining_features.remove(least_important_feature)\n",
        "\n",
        "# Prepare new feature sets\n",
        "X_train_reduced = X_train[:, :len(remaining_features)]\n",
        "X_test_reduced = X_test[:, :len(remaining_features)]\n",
        "\n",
        "# Retrain the model on the reduced feature set\n",
        "model_reduced = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model_reduced.fit(X_train_reduced, y_train)\n",
        "\n",
        "# Make predictions and evaluate the reduced model\n",
        "y_pred_reduced = model_reduced.predict(X_test_reduced)\n",
        "mse_reduced = mean_squared_error(y_test, y_pred_reduced)\n",
        "\n",
        "print(f\"Removed feature: {least_important_feature}, MSE after removal: {mse_reduced}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTq83UzGnqnA",
        "outputId": "b36eb41d-87d5-4f61-80cd-a6614537c6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature importances:\n",
            "           Feature  Importance\n",
            "7    BuildingArea    0.368577\n",
            "1        Distance    0.156417\n",
            "8       YearBuilt    0.117948\n",
            "9       Lattitude    0.078950\n",
            "2        Postcode    0.078624\n",
            "6        Landsize    0.069979\n",
            "10     Longtitude    0.060464\n",
            "11  Propertycount    0.018377\n",
            "4        Bathroom    0.015139\n",
            "0           Rooms    0.013745\n",
            "5             Car    0.012759\n",
            "3        Bedroom2    0.009021\n",
            "Removed feature: Bedroom2, MSE after removal: 65056356982.440735\n"
          ]
        }
      ]
    }
  ]
}